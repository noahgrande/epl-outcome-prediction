<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Your Project Title Here | Advanced Programming 2025</title>
    <meta name="description" content="Course materials and resources for Advanced Programming at UNIL">
    <link rel="stylesheet" href="/course-materials/assets/css/style.css">
    <link rel="canonical" href="https://ap-unil-2025.github.io/course-materials/assets/templates/project_report_template_md.txt">
    
    <!-- Favicons -->
    <link rel="icon" type="image/svg+xml" href="/course-materials/favicon.svg">
    <link rel="icon" type="image/svg+xml" sizes="32x32" href="/course-materials/favicon-32x32.svg">
    <link rel="apple-touch-icon" href="/course-materials/apple-touch-icon.svg">
    <link rel="mask-icon" href="/course-materials/favicon.svg" color="#003aff">
    <meta name="theme-color" content="#003aff">
    
    <!-- Citation Metadata -->
    <meta name="citation_title" content="Your Project Title Here">
    <meta name="citation_author" content="Scheidegger, Simon">
    <meta name="citation_author" content="Smirnova, Anna">
    <meta name="citation_publication_date" content="2025">
    <meta name="citation_journal_title" content="HEC Lausanne Course Materials">
    <meta name="citation_public_url" content="https://ap-unil-2025.github.io/course-materials/assets/templates/project_report_template_md.txt">
    <meta name="citation_pdf_url" content="https://ap-unil-2025.github.io/course-materials/assets/course-materials.pdf">
    
    <!-- Dublin Core Metadata -->
    <meta name="DC.title" content="Your Project Title Here">
    <meta name="DC.creator" content="Simon Scheidegger">
    <meta name="DC.creator" content="Anna Smirnova">
    <meta name="DC.subject" content="Data Science">
    <meta name="DC.subject" content="Python Programming">
    <meta name="DC.subject" content="Machine Learning">
    <meta name="DC.subject" content="Statistical Learning">
    <meta name="DC.description" content="Advanced course introducing Python programming, statistical learning, and high-performance computing for Master's students in Economics and Finance">
    <meta name="DC.publisher" content="HEC Lausanne, University of Lausanne">
    <meta name="DC.date" content="2025-12-17">
    <meta name="DC.type" content="Course Materials">
    <meta name="DC.format" content="text/html">
    <meta name="DC.identifier" content="https://ap-unil-2025.github.io/course-materials/assets/templates/project_report_template_md.txt">
    <meta name="DC.language" content="en">
    <meta name="DC.rights" content="Creative Commons Attribution-ShareAlike 4.0 International License">
    
    <!-- Schema.org structured data for Google Scholar -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Course",
      "name": "Data Science and Advanced Programming 2025",
      "description": "Advanced course introducing Python programming, statistical learning, and high-performance computing",
      "provider": {
        "@type": "Organization",
        "name": "HEC Lausanne, University of Lausanne",
        "sameAs": "https://www.unil.ch/hec/"
      },
      "instructor": [
        {
          "@type": "Person",
          "name": "Simon Scheidegger",
          "url": "https://sites.google.com/site/simonscheidegger/"
        },
        {
          "@type": "Person",
          "name": "Anna Smirnova"
        }
      ],
      "courseCode": "DSAP2025",
      "hasCourseInstance": {
        "@type": "CourseInstance",
        "courseMode": "https://schema.org/OnlineOnly",
        "startDate": "2025-09-15",
        "endDate": "2025-12-15",
        "location": {
          "@type": "Place",
          "name": "Internef 263",
          "address": {
            "@type": "PostalAddress",
            "addressLocality": "Lausanne",
            "addressCountry": "CH"
          }
        }
      },
      "license": "https://creativecommons.org/licenses/by-sa/4.0/"
    }
    </script>
    
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Your Project Title Here | Advanced Programming 2025</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Your Project Title Here" />
<meta name="author" content="Your Name (your.email@unil.ch)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Course materials and resources for Advanced Programming at UNIL" />
<meta property="og:description" content="Course materials and resources for Advanced Programming at UNIL" />
<link rel="canonical" href="https://ap-unil-2025.github.io/course-materials/assets/templates/project_report_template_md.txt" />
<meta property="og:url" content="https://ap-unil-2025.github.io/course-materials/assets/templates/project_report_template_md.txt" />
<meta property="og:site_name" content="Advanced Programming 2025" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-12-01T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Your Project Title Here" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Your Name (your.email@unil.ch)"},"dateModified":"2025-12-01T00:00:00+00:00","datePublished":"2025-12-01T00:00:00+00:00","description":"Course materials and resources for Advanced Programming at UNIL","headline":"Your Project Title Here","mainEntityOfPage":{"@type":"WebPage","@id":"https://ap-unil-2025.github.io/course-materials/assets/templates/project_report_template_md.txt"},"url":"https://ap-unil-2025.github.io/course-materials/assets/templates/project_report_template_md.txt"}</script>
<!-- End Jekyll SEO tag -->

</head>
<body>
    <header class="site-header">
        <div class="wrapper">
            <nav class="site-nav" role="navigation" aria-label="Main navigation">
    <div class="site-branding">
        <a class="site-title" href="/course-materials/" aria-label="Homepage">
            <img src="/course-materials/assets/images/unil.jpeg" alt="UNIL Logo" class="site-logo">
            <span class="site-title-text">DSAP</span>
        </a>
        <a href="https://nuvolos.cloud" target="_blank" rel="noopener noreferrer" class="powered-by-header" aria-label="Powered by Nuvolos">
            <span class="powered-text">Powered by</span>
            <img src="/course-materials/assets/images/nuvolos_logo.svg" alt="Nuvolos" class="header-nuvolos-logo">
        </a>
    </div>
    
    <button class="nav-toggle" aria-label="Toggle navigation menu" aria-expanded="false">
        <span class="hamburger"></span>
        <span class="hamburger"></span>
        <span class="hamburger"></span>
    </button>
    
    <div class="nav-links" id="nav-links">
        <a href="/course-materials/" >Home</a>
        <a href="/course-materials/syllabus" >Syllabus</a>
        <a href="/course-materials/weekly-materials" >Weekly Materials</a>
        <a href="/course-materials/assignments" >Assignments</a>
        <a href="/course-materials/exercises" >Exercises</a>
        <a href="/course-materials/projects" >Projects</a>
        <a href="/course-materials/help-support" >Help & Support</a>
        <a href="/course-materials/citation" >Cite</a>
        
        
    </div>
</nav>

<script>
document.addEventListener('DOMContentLoaded', function() {
    const navToggle = document.querySelector('.nav-toggle');
    const navLinks = document.querySelector('.nav-links');
    
    if (navToggle && navLinks) {
        navToggle.addEventListener('click', function() {
            const isExpanded = navToggle.getAttribute('aria-expanded') === 'true';
            navToggle.setAttribute('aria-expanded', !isExpanded);
            navLinks.classList.toggle('active');
            document.body.classList.toggle('nav-open');
        });
        
        // Close menu when clicking outside
        document.addEventListener('click', function(event) {
            if (!navToggle.contains(event.target) && !navLinks.contains(event.target)) {
                navToggle.setAttribute('aria-expanded', 'false');
                navLinks.classList.remove('active');
                document.body.classList.remove('nav-open');
            }
        });
        
        // Close menu on escape key
        document.addEventListener('keydown', function(event) {
            if (event.key === 'Escape') {
                navToggle.setAttribute('aria-expanded', 'false');
                navLinks.classList.remove('active');
                document.body.classList.remove('nav-open');
            }
        });
    }
});
</script>

<style>
/* Make navigation more compact */
.site-nav {
    padding: 0.5rem 0;
}

.nav-links {
    gap: 0.75rem;
    font-size: 0.9rem;
}

.nav-links a {
    padding: 0.25rem 0.4rem;
}

.powered-by-header {
    gap: 0.3rem;
}

.powered-text {
    font-size: 0.75rem;
}

.header-nuvolos-logo {
    height: 20px;
}

.nav-toggle {
    display: none;
    background: none;
    border: none;
    cursor: pointer;
    padding: 0.5rem;
    flex-direction: column;
    gap: 0.25rem;
    z-index: 1001;
}

.hamburger {
    width: 24px;
    height: 2px;
    background-color: var(--text-primary);
    transition: all 0.3s ease;
    transform-origin: center;
}

.nav-toggle[aria-expanded="true"] .hamburger:nth-child(1) {
    transform: rotate(45deg) translate(6px, 6px);
}

.nav-toggle[aria-expanded="true"] .hamburger:nth-child(2) {
    opacity: 0;
}

.nav-toggle[aria-expanded="true"] .hamburger:nth-child(3) {
    transform: rotate(-45deg) translate(6px, -6px);
}

.nav-links a.active {
    color: var(--primary-color);
    font-weight: 600;
    background-color: rgba(59, 130, 246, 0.05);
}

/* Hide the underline pseudo-element completely */
.nav-links a::after {
    display: none !important;
}

.external-links {
    margin-left: 2rem;
    padding-left: 2rem;
    border-left: 1px solid var(--border-color);
}

.external-icon {
    font-size: 0.8em;
    opacity: 0.7;
    margin-left: 0.25rem;
}

@media (max-width: 768px) {
    .site-nav {
        position: relative;
    }
    
    .nav-toggle {
        display: flex;
    }
    
    .nav-links {
        position: absolute;
        top: 100%;
        left: 0;
        right: 0;
        background-color: var(--background-color);
        border: 1px solid var(--border-color);
        border-top: none;
        border-radius: 0 0 0.5rem 0.5rem;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        flex-direction: column;
        gap: 0;
        padding: 1rem 0;
        transform: translateY(-10px);
        opacity: 0;
        visibility: hidden;
        transition: all 0.3s ease;
        z-index: 1000;
    }
    
    .nav-links.active {
        transform: translateY(0);
        opacity: 1;
        visibility: visible;
    }
    
    .nav-links a {
        padding: 0.75rem 1.5rem;
        display: block;
        color: var(--text-primary);
        border-bottom: 1px solid var(--border-color);
    }
    
    .nav-links a:last-child {
        border-bottom: none;
    }
    
    .nav-links a:hover {
        background-color: var(--surface-color);
    }
    
    .nav-links a::after {
        display: none;
    }
    
    .external-links {
        margin-left: 0;
        padding-left: 0;
        border-left: none;
        border-top: 1px solid var(--border-color);
        padding-top: 1rem;
        margin-top: 1rem;
    }
    
    body.nav-open {
        overflow: hidden;
    }
}
</style>
        </div>
    </header>

    <main class="page-content page-transition">
        <div class="wrapper page-wrapper">
            
            
            <article class="page">
    <header class="page-header">
        <h1 class="page-title">Your Project Title Here</h1>
        
        <p class="page-subtitle">Advanced Programming 2025 - Final Project Report</p>
        
    </header>

    <div class="page-content">
        
# Abstract

Predicting the outcome of football matches is challenging. The various aspects of the game from team performance, tactical choices to diverse situations all play an important role in the result. This project investigates whether historical match statistics are meaningful to predict the outcome of football matches of the English Premier League.
Using real Premier League data, a dataset was constructed from publicly available match statistics and bookmaker odds from season 2021/22 to 2024/25, representing approximately 1400 matches. The data preparation work included data cleaning, merging datasets, feature selection and the creation of recent form rolling indicator, capturing differences between home and away teams. Two machine learning models, Logistic Regression and Random Forest classifier, were implemented to estimate outcome probabilities. The performance of the model was evaluated using standard classification metrics such as accuracy, log loss and confusion matrix on unseen data. Moreover, predictions of the model were compared to the implied probabilities of bookmakers, which serve as a strong baseline reflecting aggregated market information. The results show that the models achieve reasonable predictive performance and capture meaningful relationships between match statistics and result, while still exhibiting limitations when compared to bookmaker probabilities.
This project outlines a full data science workflow, from data preparation to model evaluation, to examine if the outcome of a match can be predicted using historical match data, and how the probability estimates produced by machine learning models compare to those implied by bookmaker odds.

**Keywords:** data science, Python, machine learning, [add your keywords]

\newpage

# Table of Contents

1. [Introduction](#introduction)
2. [Literature Review](#literature-review)
3. [Methodology](#methodology)
4. [Results](#results)
5. [Discussion](#discussion)
6. [Conclusion](#conclusion)
7. [References](#references)
8. [Appendices](#appendices)

\newpage

# 1. Introduction

Football is the most recognized and the most well-known sport in the world. The English premier league is arguably the most entertaining and the best league in the world. But it is more than just an extremely popular sport, it is also a massive generator of publicly available data that has made football an attractive domain for computer science and machine learning applications for the analysis and the prediction of matches. Despite this load of information, the game remains challenging to forecast. The outcome of a match is difficult to predict due to the influence of many factors from the weather to detailed events in the match and even chance.
The main objective of this project is to investigate whether historical match statistics can be a good predictor of the results of the matches, defined as home win, away win or draw. The goal is not to produce a betting system or to outperform the bookmakers, it is to understand the relationship between performance indicators and the result. in this context, bookmakersâ€™ odds are not viewed as a target to reach or even to beat, but as a sophisticated base of comparison that represent the intelligence of the market.
To address this problem a dataset was constructed using real match statistics such as goals, passing metrics, discipline and betting odds. The features used for the model were designed to capture relative differences between the home and away team, a common choice in football predictions. the features used include recent performance indicators, goal related metrics and advanced statistics, all averaged to a certain period to exclude data leakage. two machine learning models including logistic regression and random forest classifiers were used to estimate outcome probabilities based on these features.
This report walks through the entire process, from feature engineering and model training to a critical look at where statistical models succeed and where they fall short.

# 2. Literature Review

Predicting football match outcomes has long been a subject of interest in both statistics and data science and has evolved massively due to the increasing amount of data provided. In most studies the task has been formulated as a three possible outcome classification problem, home win, draw or away win. Football presents a particularly challenging prediction problem due to its inherent uncertainty, the high impact of random events, and the strong interdependence between competing teams. Therefore, even with well-designed models, perfect prediction is practically unattainable.
Early research on football prediction relied primarily on statistical model such as Poisson regression and goal-scoring processes. These approaches provided important foundations and introduced key assumptions about team strengths and match dynamics, but they often struggled to capture complex relationships between teams and contextual factors (1,2). More recent work has shifted towards machine learning models including Logistic Regression, Random Forest and Gradient Boosting models (3, 4, 8, 9) which are better suited to handle non-linear patterns and the large amount of data generated.
The difficulty of predicting draws is the main challenge of todayâ€™s research. Several studies report that machine learning models tend to perform well in two factors model while draws are often poorly predicted or entirely ignored by the model (10). This issue is commonly attributed to class imbalance ad draws occurs less than wins or losses. To address this problem, some researchers reformulate the prediction task as a binary classification problem, such as predicting home win versus non-home win, which has been shown to improve overall predictive performance (5).
Feature engineering plays a central role in football match prediction. Many studies highlight the importance of using features that are known prior to match kick-off in order to ensure realistic predictive scenarios (3, 19). 
The most common features used include aggregated match statistics from previous games, such as shots, goals, possession, and disciplinary records, often computed as averages over a fixed number of recent matches. In addition, advanced performance indicators such as expected goals have gained popularity, as they provide a more representative and predictive information than the goal (10). Another commonly adopted strategy is the use of relative features including differences in performances and in recent form and strength. By focusing on differences rather than absolute values, these metrics directly encode competitive balance and home advantage effects, which are known to influence match outcomes (7, 8, 11). Ratings derived from external sources, such as FIFA ratings or league rankings, are also frequently used as proxies for team strength and long-term performance (11).
Finally, bookmakersâ€™ odds are often used as a benchmark for evaluating predictive models. They represent the intelligence of the market and aggregate a large amount of information making their probabilities and prediction difficult to outperform (12,13). Rather than trying to make profit on the bookmakers, several studies use bookmakersâ€™ odds as a baseline to assess whether their models capture meaningful information beyond what ius already reflected in the market prices (13,14). 
Overall, existing research suggests that machine learning models can achieve reasonable predictive performance when applied to football match data, particularly when careful feature engineering and problem formulation are employed (3, 5, 10). However, limitations related to class imbalance, draw prediction, and model generalization remain significant. This project builds on prior work by adopting a structured machine learning approach, emphasizing relative performance features, probabilistic evaluation, and comparison to bookmaker-based baselines within an academic data science framework (6, 18, 20).

# 3. Methodology

## 3.1 Data Description

The datasets used include both raw and processed data covering Premier League seasons from 2021 up to January 2025. The data collection period ends in January 2025 due to the absemce of values in the records. The choice to focus on seasons from 2021 onward is motivated by the structural and tactical evolution of the Premier League in recent years. As the league has undergone noticeable changes in playing style and competitive dynamics, restricting the analysis to more recent seasons ensures greater relevance and consistency with the current football context.
The first raw dataset used in this project consists of historical football match data from the English Premier League, collected from publicly available football statistics sources and Kaggle, named matchdata_21-25.csv in the project. The data span multiple seasons, from 2021/22 to 2024/25 (January) and is structured at the match level, with each line corresponding to a single game from one team point of view, consisting of 1â€™369 games so 2738 lines. The dataset contains 152 columns with each one corresponding to a single match statistic, such as goals metrics, passing stats, advanced statistics such as xG, etc. The second part of raw datasets are 4 datasets, one of each season named 21_22, 22_23, 23_24 and 24_25 coming from the website football data.co.uk. This dataset contains match statistics combined with loads of bookmakersâ€™ odds. Each line regards one single game from both home and away perspective. All these four are merged in all_matches.csv to contain every game of every season, until January 2025 to facilitate the merge and a match_id is also created for convenience. Only match statistics and certain odds are kept. Then, both processed data sets are merged using the match_id and processed to keep only the useful columns. The features in the dataset being known before the match, rolling statistics are created to keep only information known before the game. After data cleaning and preprocessing, the intermediate dataset (data_after_engineering.csv) contains 1â€™369 matches, one line per team for each match, so two lines per match, and a structured set of numerical features, including rolling features of match statistics such as avg_goals_for_L5, avg_xg_against_L5, avg_discipline_L5. Rolling features caused a loss of approximately 80 games to the model due to the absence of value for the first matches. Rolling features were restarted each start of the season and for the first 4 games the average was taken not on the last 5 games but on the number of games played before. The target variable is a categorical match outcome (target) with three classes: home win, draw, and away win, which is the standard multiclass setup in football prediction research (3, 5).
The model training set, (model_data.csv) is composed exclusively of variables available prior to kick-off, ensuring a realistic predictive setting. Each line corresponds to one game. Most of these features are computed as differences between the home and away teams, capturing relative strengths rather than absolute levels. These include differences in recent form indicators such as average points over the last 5 and 10 matches (diff_avg_points_L5, diff_avg_points_L10), offensive and defensive performance (diff_avg_goals_for_L5, diff_avg_goals_against_L5), clean sheet rates (diff_clean_sheet_rate_L5), expected goals metrics (diff_avg_xg_for_L5, diff_avg_xg_against_L5, diff_avg_xg_diff_L5), and goal difference (diff_avg_goal_diff_L5). The dataset further includes differences in match statistics such as shots on target (diff_avg_shots_on_target_for_L5, diff_avg_shots_on_target_against_L5), possession (diff_avg_possession_L5), saves (diff_avg_saves_L5), fouls (diff_avg_fouls_L5), yellow cards (diff_avg_yellow_cards_L5), blocks (diff_avg_blocks_L5), and clearances (diff_avg_clearances_L5). Contextual home/away form is also captured via features such as diff_avg_points_home_L5 and diff_avg_points_away_L5.
Crucially, as explained earlier, the dataset also includes bookmaker odds as market-based information available before kick-off. This includes three-way outcome odds for home win, draw, and away win (odds_win, odds_draw, odds_lose), as well as goal-market odds for over/under 2.5 goals (odds_over25, odds_under25). These variables are used as a strong benchmark reflecting aggregated public and expert information, and they serve as a baseline for comparison with model-predicted probabilities and are therefore not included in the model (12, 13).

## 3.2 Approach

This project adopts a supervised machine learning approach to predict football match outcomes. The task is formulated as a multiclass classification problem with three possible outcomes: home win, draw, and away win. This formulation is standard in the football prediction literature and reflects the natural structure of match results (3, 5).

Algorithms

Two classification models are employed in this study: logistic regression and random forest. Logistic regression is used as a baseline machine learning model due to its simplicity, interpretability, and ability to produce well-calibrated probabilistic outputs. Its linear structure provides a transparent reference point and facilitates comparison with more flexible models.
Random forest is selected as a representative ensemble method based on decision trees. By aggregating predictions from multiple trees, the model is able to capture nonlinear relationships and complex interactions between features while remaining robust to noise and outliers (8, 9, 15). This makes random forest particularly suitable for heterogeneous football performance data composed of tactical, statistical, and market-based features.
Bookmaker odds are not used as the sole predictive objective and are not included as input features in the machine learning models. They are used separately as an external benchmark for comparison with model-predicted probabilities. Model predictions are explicitly compared against bookmaker-implied probabilities in order to contextualize model performance relative to market expectations (12, 13).

Preprocessing

Data preprocessing consists of several steps applied uniformly across models. Observations with missing values are removed to ensure a consistent feature set. Rolling features were created to ensure models use only information available prior to kick-off. They were constructed in this manner:

```python 
df["avg_points_L5"] = g["points"].shift(1).rolling(5, min_periods=1).mean()
```

this example from the build_rolling_features function shows the arcitecture of the rolling features. It is a mean of the last five games, starting after the first game and if the numer of matche <5, taking the number of matches before to make the mean and also banning the actual match. This function allows the model to use only information available prior the match. The model uses data available in the file model_data and that is differences between home and away team. These features are created in this boucle:

```python 
for c in feature_cols:
out[f"diff_{c}"] = (
merged[f"{c}_home"] - merged[f"{c}_away"]
)
```

This boucle is taking the value from home and from away team and create a difference from all rolling features. Differences are mainly used in studies and are highly significant to predict match outcomes.
For logistic regression, numerical features are standardized to zero mean and unit variance to improve numerical stability and model convergence. For random forest, features are left unscaled, as tree-based models are invariant to monotonic transformations. No explicit outlier removal is performed, as ensemble tree models are generally robust to extreme values. Feature selection is guided by domain knowledge and correlation-based considerations (see tables in the code) in order to reduce redundancy and limit overfitting, following standard feature engineering practices in machine learning (18, 19).

Model Architecture

The logistic regression model is used to estimate the probability of each possible match outcome: home win, draw, or away win. For every match, the model outputs a probability for each class and predicts the outcome with the highest probability. Regularization is applied to prevent the model from overfitting the training data and to improve its ability to generalize to unseen matches. The random forest model is an ensemble method composed of many decision trees trained on different subsets of the data. Each tree learns simple decision rules based on a random selection of features, which introduces diversity among the trees. The final prediction is obtained by averaging the probabilities produced by all trees, resulting in a more stable and robust prediction.
Both models are implemented using the scikit-learn library, which provides a consistent framework for model training, probability estimation, and evaluation. This ensures a fair comparison between models and facilitates reproducibility of the results.

Evaluation Metrics

Model performance is evaluated using both accuracy and probabilistic metrics. Accuracy gives a general indication of how often the model predicts the correct outcome, but it is not sufficient on its own because match outcomes are imbalanced, with draws occurring less frequently than wins or losses. For this reason, additional evaluation focuses on the predicted probabilities. Metrics such as log loss are used to measure how well the predicted probabilities reflect the true match outcomes. This is particularly relevant when comparing model predictions to bookmaker-implied probabilities, which are also expressed in probabilistic terms (6).
Performance is analysed both overall and for each outcome class separately. Special attention is given to the draw class, which is know to be challenging to predict and represents a limitation in football match prediction models (5, 10).

## 3.3 Implementation

The project is implemented entirely in Python, using standard data science libraries. Data manipulation and preprocessing are handled with pandas and numpy. Machine learning models are implemented using the scikit-learn library, which provides a unified interface for model training, probability estimation, and evaluation. Model persistence is managed with joblib, allowing trained models to be saved and reused in a consistent manner.
The overall system architecture follows a modular and reproducible pipeline design. Raw match data are first loaded and sorted chronologically to prevent information leakage. Relevant features are selected and validated to avoid redundance, after which the dataset is split chronologically into training and test sets (80/20) to avoid data leakage. Machine learning models are trained on the training set, evaluated on the test set, and stored together with evaluation outputs and metadata.
Main part of the project is the treatment of data including loading, standardizing, merging, feature selection and rolling features creation. Other key components of the implementation include scripts responsible for model training, evaluation, and result storage. Logistic regression is implemented using a pipeline that combines feature standardization and model fitting, ensuring that preprocessing steps are applied consistently. Random forest models are trained without feature scaling and provide feature importance scores that support model interpretation.
For each model, classification reports, confusion matrices, and probabilistic evaluation metrics are generated and saved to disk. Trained models and the list of features used during training are also stored, ensuring reproducibility and consistency between training and prediction phases. This implementation strategy follows the software engineering and reproducibility principles emphasized in the course.

# 4. Results

## 4.1 Experimental Setup

All experiments were conducted in a CPU-only environment on a standard personal computer. The implementation was carried out in Python using widely adopted data science libraries, notably pandas for data manipulation and scikit-learn for model training, preprocessing, and evaluation. The full training and evaluation procedure is reproducible and executed locally.
To avoid temporal leakage, matches were first sorted chronologically by match_date and then split into training and test sets using an 80/20 chronological split. Approximately 80% of the observations (1,027 matches) were used for training, while the remaining 20% (257 matches) were reserved for out-of-sample testing.

```python
df = df.sort_values("match_date")
split_idx = int(len(x) * 0.8)
```

For logistic regression, a multinomial formulation was used together with feature standardization via a StandardScaler. Model training relied on the LBFGS optimizer with an increased maximum number of iterations to ensure convergence. 

```python
log_reg = Pipeline([
    ("scaler", StandardScaler()),
    ("clf", LogisticRegression(
        solver="lbfgs",
        max_iter=2000,
        random_state=42
    ))
])
```

The random forest model was trained using 300 decision trees, with a minimum number of samples per leaf set to reduce overfitting. Default impurity-based splitting criteria were used.

```python
rf = RandomForestClassifier(
    n_estimators=300,
    min_samples_leaf=5,
    random_state=42,
    n_jobs=-1
)
```

No cross-validation or extensive hyperparameter tuning was performed, as the primary objective of the project is comparative and methodological rather than performance optimization.

## 4.2 Performance Evaluation

Present your results with tables and figures.

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| Baseline | 0.75 | 0.72 | 0.78 | 0.75 |
| Your Model | 0.85 | 0.83 | 0.87 | 0.85 |

*Table 1: Model performance comparison*

## 4.3 Visualizations

Include relevant plots and figures:

- Learning curves
- Confusion matrices
- Feature importance plots
- Results visualizations

![Example Results](path/to/figure.png)
*Figure 1: Description of your results*

# 5. Discussion

Analyze and interpret your results:

- **What worked well?** Successful aspects of your approach
- **Challenges encountered**: Problems faced and how you solved them
- **Comparison with expectations**: How do results compare to hypotheses?
- **Limitations**: What are the constraints of your approach?
- **Surprising findings**: Unexpected discoveries

# 6. Conclusion

## 6.1 Summary

Summarize your key findings and contributions:

- Main achievements
- Project objectives met
- Impact of your work

## 6.2 Future Work

Suggest potential improvements or extensions:

- Methodological improvements
- Additional experiments to try
- Real-world applications
- Scalability considerations

# References

1. Author, A. (2024). *Title of Article*. Journal Name, 10(2), 123-145.

2. Smith, B. & Jones, C. (2023). *Book Title*. Publisher.

3. Dataset Source. (2024). Dataset Name. Available at: https://example.com

4. Library Documentation. (2024). *Library Name Documentation*. https://docs.example.com

# Appendices

## Appendix A: Additional Results

Include supplementary figures or tables that support but aren't essential to the main narrative.

## Appendix B: Code Repository

**GitHub Repository:** https://github.com/yourusername/project-repo

### Repository Structure

```
project-repo/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ evaluation.py
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb
â””â”€â”€ results/
    â””â”€â”€ figures/
```

### Installation Instructions

```bash
git clone https://github.com/yourusername/project-repo
cd project-repo
pip install -r requirements.txt
```

### Reproducing Results

```bash
python src/main.py --config config.yaml
```

---

*Note: This report should be exactly 10 pages when rendered. Use the page count in your PDF viewer to verify.*

---

## Conversion to PDF

To convert this Markdown file to PDF, use pandoc:

```bash
pandoc project_report.md -o project_report.pdf --pdf-engine=xelatex
```

Or with additional options:

```bash
pandoc project_report.md \
  -o project_report.pdf \
  --pdf-engine=xelatex \
  --highlight-style=pygments \
  --toc \
  --number-sections
```
    </div>
</article>
        </div>
    </main>

    <footer class="site-footer">
        <div class="wrapper">
            <p class="license">
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
                    <img alt="Creative Commons License" style="border-width:0; height: 31px; width: auto; display: block; margin: 0 auto 0.5rem auto;" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" />
                </a>
                This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p class="citation">
                <strong>Cite as:</strong> Scheidegger, S., & Smirnova, A. (2025). <em>Data Science and Advanced Programming 2025</em>. HEC Lausanne, University of Lausanne. 
                <a href="/course-materials/citation">View citation formats â†’</a>
            </p>
            <p class="credits">Made with ðŸ’™ by Anna Smirnova, Prof. Simon Scheidegger, and Claude ðŸ¤–</p>
            <p class="powered-by">
                <a href="https://nuvolos.cloud" target="_blank" style="display: inline-flex; align-items: center; gap: 0.5rem; color: inherit; text-decoration: none;">
                    Powered by
                    <img src="/course-materials/assets/images/nuvolos_logo.svg" alt="Nuvolos" style="height: 20px; width: auto; opacity: 0.8;">
                </a>
            </p>
        </div>
    </footer>

    <!-- Smooth Page Transitions -->
    <style>
    /* No CSS transitions - just AJAX navigation */
    
    /* Smooth scrolling for same-page links */
    html {
        scroll-behavior: smooth;
    }
    
    /* Removed underline animation - clean hover effect only */
    </style>

    <script>
    // Smooth SPA-style navigation
    document.addEventListener('DOMContentLoaded', function() {
        const pageContent = document.querySelector('.page-wrapper');
        const navLinks = document.querySelectorAll('.nav-links a');
        
        // Handle navigation clicks with AJAX
        navLinks.forEach(link => {
            // Skip external links
            if (link.hostname !== window.location.hostname) {
                return;
            }
            
            link.addEventListener('click', function(e) {
                e.preventDefault();
                
                const url = this.href;
                const currentPath = window.location.pathname;
                
                // Skip if same page
                if (url === window.location.href) {
                    return;
                }
                
                // Fetch new page content
                fetch(url)
                    .then(response => response.text())
                    .then(html => {
                        // Parse the new page
                        const parser = new DOMParser();
                        const newDoc = parser.parseFromString(html, 'text/html');
                        const newContent = newDoc.querySelector('.page-wrapper');
                        const newTitle = newDoc.querySelector('title');
                        
                        // Update content instantly
                        if (newContent) {
                            pageContent.innerHTML = newContent.innerHTML;
                            
                            // Re-execute any script tags in the new content
                            const scripts = pageContent.querySelectorAll('script');
                            scripts.forEach(script => {
                                const newScript = document.createElement('script');
                                if (script.src) {
                                    newScript.src = script.src;
                                } else {
                                    newScript.textContent = script.textContent;
                                }
                                script.parentNode.replaceChild(newScript, script);
                            });
                        }
                        if (newTitle) {
                            document.title = newTitle.textContent;
                        }
                        
                        // Update URL without reload
                        history.pushState({}, '', url);
                        
                        // Update active navigation
                        updateActiveNav(url);
                        
                        // Scroll to top
                        window.scrollTo({ top: 0, behavior: 'smooth' });
                    })
                    .catch(error => {
                        console.log('AJAX failed, falling back to normal navigation');
                        window.location.href = url;
                    });
            });
        });
        
        // Handle browser back/forward
        window.addEventListener('popstate', function() {
            window.location.reload();
        });
        
        // Update active navigation state
        function updateActiveNav(currentUrl) {
            navLinks.forEach(link => {
                link.classList.remove('active');
                if (link.href === currentUrl || 
                    (currentUrl.includes('/week/') && link.href.includes('/weekly-materials'))) {
                    link.classList.add('active');
                }
            });
        }
        
        // Initial active state
        updateActiveNav(window.location.href);
    });
    </script>
</body>
</html>